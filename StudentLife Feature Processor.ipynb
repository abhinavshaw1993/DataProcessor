{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from IPython.display import display, HTML\n",
    "import numpy as np\n",
    "from sklearn.utils import resample\n",
    "from IPython.display import display\n",
    "import numpy as np\n",
    "import datetime\n",
    "import os\n",
    "\n",
    "# Create a connection with SQL server to get data.\n",
    "def exec_sql_query(query, param=None):\n",
    "    \n",
    "    from sqlalchemy import create_engine\n",
    "    import urllib\n",
    "    params = urllib.parse.quote_plus(\"DRIVER={SQL Server Native Client 11.0};SERVER=LAPTOP-C3LFVOFI;DATABASE=student_life;UID=student_sense;PWD=abhinav123\")\n",
    "    engine = create_engine(\"mssql+pyodbc:///?odbc_connect=%s\" % params)\n",
    "    connection = engine.raw_connection()\n",
    "    \n",
    "    try:\n",
    "        cursor = connection.cursor()\n",
    "        if(param):\n",
    "            cursor.execute(query, param)\n",
    "        else : \n",
    "            cursor.execute(query)\n",
    "            \n",
    "        results = cursor.fetchall()\n",
    "        columns = [column[0] for column in cursor.description]\n",
    "        df = pd.DataFrame.from_records(results, columns=columns)\n",
    "        cursor.close()\n",
    "        connection.commit()\n",
    "    finally:\n",
    "        connection.close()\n",
    "    \n",
    "    del engine\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature_query_for_student(dictionary, student_id):\n",
    "\n",
    "    for key in dictionary.keys():\n",
    "        dictionary[key] = dictionary[key]  + \" where student_id = \"+str(student_id) \n",
    "    \n",
    "    return dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Students:  [0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20, 22, 23, 24, 25, 27, 30, 31, 32, 33, 34, 35, 36, 39, 41, 42, 43, 44, 45, 46, 47, 49, 50, 51, 52, 53, 54, 56, 57, 58, 59]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Maintaining a feature list.\n",
    "base_feature_map = {\n",
    "\n",
    "    \"activity_details\" : \"SELECT activity_time ,student_id ,activity_inference FROM activity_details \",\n",
    "    \n",
    "    \"dinning_details\" : \"SELECT dinning_time ,student_id ,venue_id ,meal_type_id FROM dinning_details  \",\n",
    "    \n",
    "    \"call_log_details\" : \"select timestamp as call_time, student_id, 1 as call_recorded  from call_log_details\",\n",
    "    \n",
    "    \"sms_details\" : \"select timestamp, student_id, 1 from sms_details \",\n",
    "    \n",
    "    \"audio_details\" : \"select audio_activity_time, student_id, audio_activity_inference from audio_details \",\n",
    "    \n",
    "    \"conversation_details\" : \"select conv_start_timestamp, student_id, conv_duration_min from conversation_details \",\n",
    "    \n",
    "    \"dark_details\" : \"select dark_start_timestamp, student_id, dark_duration_min from dark_details \",\n",
    "    \n",
    "    \"phonecharge_details\" : \"select start_timestamp, student_id, phonecharge_duration_min from phonecharge_details \",\n",
    "\n",
    "    \"phonelock_details\" : \"select start_timestamp, student_id, phonelock_duration_min from phonelock_details \",\n",
    "     \n",
    "    \"gps_details\" : \"select wifi_timestamp as time, student_id, latitude, longitude from gps_details \"\n",
    "    \n",
    "                         }\n",
    "base_feature_map = {\n",
    "    \n",
    "    \"sleep_details\" : \"select response_timestamp, student_id, hours_slept, sleep_rating from sleep_details\"\n",
    "    \n",
    "}\n",
    "# base_feature_map = {\n",
    "#     \"dinning_details\" : \"SELECT dinning_time ,student_id ,venue_id ,meal_type_id FROM dinning_details  \"\n",
    "#     }\n",
    "\n",
    "# Collecting distinct students.\n",
    "distinct_students = exec_sql_query(\"select distinct student_id from stress_details\")\n",
    "distinct_students = distinct_students.values.T.tolist()\n",
    "distinct_students = distinct_students[0]\n",
    "distinct_students.sort()\n",
    "\n",
    "# getting current working directory for creating directories later.\n",
    "cwd = os.getcwd()\n",
    "\n",
    "# distinct_students = distinct_students[10:20]\n",
    "print(\"Students: \", distinct_students)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty Dataframe for Student 13 for feature sleep_details\n"
     ]
    }
   ],
   "source": [
    "for student in distinct_students:\n",
    "    newpath = r'\\StudentLife Data\\student '+ str(student) \n",
    "    newpath = cwd + newpath\n",
    "\n",
    "    if not os.path.exists(newpath):\n",
    "        os.makedirs(newpath)\n",
    "    \n",
    "    # Getting Stress levels for only student_id = 1. This will be merged with other features.\n",
    "    stress_details_raw = exec_sql_query(\"select student_id, response_time, stress_level from stress_details where student_id = \"+str(student))\n",
    "    stress_details = stress_details_raw.loc[:,[\"response_time\",\"student_id\",\"stress_level\"]]\n",
    "    stress_details = stress_details.sort_values(by=\"response_time\")\n",
    "    stress_details.rename({\"response_time\": \"time\"}, axis='columns', inplace=True)\n",
    "\n",
    "    # Extracting first and last index of stress level. \n",
    "    # We will truncate other features 3 day behind and 3 day ahead.\n",
    "    first_date = stress_details.loc[0, 'time']\n",
    "    last_date = stress_details.loc[len(stress_details)-1, 'time']\n",
    "    \n",
    "\n",
    "    # delta to back and ahead, in days.\n",
    "    first_date = first_date - datetime.timedelta(days=3)\n",
    "    last_date = last_date + datetime.timedelta(days=0)\n",
    "    \n",
    "    feature_map = get_feature_query_for_student(base_feature_map.copy(), student)\n",
    "    \n",
    "    for key in feature_map.keys():\n",
    "\n",
    "        feature_query = feature_map[key]\n",
    "        \n",
    "#         print(feature_query)\n",
    "        # Data processing begins..\n",
    "        feature_data = exec_sql_query(feature_query)\n",
    "\n",
    "        # Selecting Time Col.\n",
    "        train_col_list = []\n",
    "\n",
    "        for col in feature_data.columns:\n",
    "            if \"time\" in col:\n",
    "                time_column = col\n",
    "            else:\n",
    "                train_col_list.append(col)\n",
    "\n",
    "        feature_data.rename({time_column: \"time\"}, axis='columns', inplace=True)\n",
    "        time_column = \"time\"\n",
    "\n",
    "        # Sorting by values of time.        \n",
    "        feature_data = feature_data.sort_values(by=time_column)\n",
    "        feature_data = feature_data.dropna()\n",
    "\n",
    "        # Truncating extra features that do not lie in the time frame.\n",
    "        feature_data = feature_data[np.logical_and(feature_data[time_column] > first_date, feature_data[time_column] < last_date)]\n",
    "                \n",
    "        if feature_data.empty:\n",
    "            print (\"Empty Dataframe for Student {} for feature {}\".format(student, key))\n",
    "            continue\n",
    "    \n",
    "        \n",
    "        train_feature_data = pd.merge_asof(stress_details,\n",
    "                                     feature_data,\n",
    "                                     direction=\"backward\",\n",
    "                                     by=\"student_id\",\n",
    "                                     on = \"time\")    \n",
    "        \n",
    "        # We need to append the other feature values as well. Creating New column for activity_details/\n",
    "        feature_data[\"stress_level\"] = np.nan \n",
    "\n",
    "        # Sorting column naming convention\n",
    "        train_col_list = []\n",
    "        \n",
    "        for col in train_feature_data.columns:\n",
    "            if col !=\"stress_level\":\n",
    "                train_col_list.append(col)\n",
    "\n",
    "        train_col_list.append('stress_level')\n",
    "        train_feature_data = train_feature_data[train_col_list]\n",
    "        \n",
    "        # Rearrainging columns\n",
    "        feature_data = feature_data[train_col_list]\n",
    "        train_feature_data = train_feature_data[train_col_list]\n",
    "        \n",
    "        train_feature_data = train_feature_data.append(feature_data, ignore_index=True)\n",
    "        train_feature_data.sort_values(by=[\"student_id\",\"time\"], inplace=True)\n",
    "        train_feature_data.reset_index(inplace=True, drop=True)\n",
    "        \n",
    "        # Filling any nulls in the feature data, but not touching the stress levels.\n",
    "        train_feature_data.iloc[:,1:-1] = train_feature_data.iloc[:,1:-1].fillna(method=\"backfill\", axis=0)\n",
    "        train_feature_x = train_feature_data\n",
    "        df_filter = train_feature_x.loc[:,[\"stress_level\"]].stress_level.notnull()\n",
    "        train_feature_y_indices = train_feature_x[df_filter].index\n",
    "        train_feature_y_indices = pd.DataFrame(train_feature_y_indices)\n",
    "        train_feature_y_indices.rename({0:\"indices\"}, axis=1, inplace=True)  \n",
    "        \n",
    "        # Saving in CSV.        \n",
    "        train_feature_x.to_csv(\"StudentLife Data/student \"+str(student)+\"/\"+key+\"_train_x.csv\", index=True)\n",
    "        train_feature_y_indices.to_csv(\"StudentLife Data/student \"+str(student)+\"/\"+key+\"_train_y_indices.csv\", index=True)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
