{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import display\n",
    "import math\n",
    "from sklearn.preprocessing import normalize\n",
    "import warnings\n",
    "from datetime import timedelta\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "owd:  F:\\Projects\\DataProcessor\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "owd = \"F:\\Projects\\DataProcessor\"\n",
    "print(\"owd: \", owd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DirList that will be precessed:  ['student 1', 'student 10', 'student 12', 'student 13', 'student 14', 'student 15', 'student 16', 'student 17', 'student 18', 'student 19', 'student 2', 'student 20', 'student 22', 'student 23', 'student 24', 'student 25', 'student 27', 'student 3', 'student 30', 'student 31', 'student 32', 'student 33', 'student 34', 'student 35', 'student 36', 'student 39', 'student 4', 'student 41', 'student 42', 'student 43', 'student 44', 'student 45', 'student 46', 'student 47', 'student 49', 'student 5', 'student 50', 'student 51', 'student 52', 'student 53', 'student 54', 'student 56', 'student 57', 'student 58', 'student 59', 'student 7', 'student 8', 'student 9']\n",
      "Working on:  student 1\n",
      "Working on:  student 10\n"
     ]
    }
   ],
   "source": [
    "os.chdir(owd)\n",
    "data_dir = owd+\"\\StudentLife Data\"\n",
    "os.chdir(data_dir)\n",
    "dir_list = [x for x in os.listdir('.') if \"student\" in x]\n",
    "\n",
    "# Skipping Student 0, because of bad data.\n",
    "dir_list = dir_list[1:]\n",
    "# dir_list = dir_list[1:3]\n",
    "print(\"DirList that will be precessed: \", dir_list)\n",
    "converter_dict = {'time':pd.to_datetime}\n",
    "\n",
    "for folder in dir_list:\n",
    "    print(\"Working on: \", folder)\n",
    "    \n",
    "    path = data_dir + \"\\\\\"+ folder\n",
    "    os.chdir(path) \n",
    "    file_list = [file[:-12]  for file in os.listdir() if \"train_x\" in file]\n",
    "    feature_test_list = []\n",
    "    feature_train_list = []\n",
    "    \n",
    "    # select student only if all the feature present.\n",
    "    \n",
    "    if (len(file_list) < 11):\n",
    "        continue\n",
    "        \n",
    "    \n",
    "    for file in file_list:\n",
    "        \n",
    "        raw_feature_train = pd.read_csv(file+ \"_train_x.csv\",\n",
    "                                          skip_blank_lines=False,\n",
    "                                          index_col=0,\n",
    "                                          converters=converter_dict)\n",
    "\n",
    "        raw_feature_train_y_indices = pd.read_csv(file+ \"_train_y_indices.csv\", \n",
    "                                                  skip_blank_lines=False, \n",
    "                                                  index_col=0)\n",
    "\n",
    "        # to bring the values from 0-4.\n",
    "        raw_feature_train[\"stress_level\"] += -1\n",
    "\n",
    "        # Hardcore indexing, to convert single index to multi so that max, min and avg can be taken easily.\n",
    "        # Train set.\n",
    "        list_a = []\n",
    "        list_b = raw_feature_train.index.values\n",
    "\n",
    "        indices = list(raw_feature_train_y_indices.indices.values)\n",
    "        indices = [-1] + indices\n",
    "\n",
    "        for indx in range(1, len(indices)) :\n",
    "            list_a += [indices[indx] for i in range(indices[indx]-indices[indx-1])]\n",
    "\n",
    "        index_keys = [\n",
    "            np.array(list_a),\n",
    "            np.array(list_b)        \n",
    "        ]\n",
    "\n",
    "        raw_feature_train.set_index(keys=index_keys, inplace=True)\n",
    "        \n",
    "        feature_list = list(raw_feature_train.columns.values) \n",
    "        feature_list.remove(\"student_id\")\n",
    "        feature_list.remove(\"time\")\n",
    "        feature_list.remove(\"stress_level\")\n",
    "        \n",
    "        # Colapsing Multindex to fin min, max and mean of the seq. \n",
    "        raw_feature_train_min = raw_feature_train.min(level=0)\n",
    "        raw_feature_train_max = raw_feature_train.max(level=0)\n",
    "        \n",
    "\n",
    "        # Mean, Median and Count also creating the column list.\n",
    "        raw_feature_train_mean = raw_feature_train.mean(level=0)\n",
    "        raw_feature_train_median = raw_feature_train.median(level=0)\n",
    "        raw_feature_train_sum = raw_feature_train.sum(level=0)\n",
    "        raw_feature_train_count = raw_feature_train.count(level=0)\n",
    "        \n",
    "        # Explicit delta given to the model. Since all the counts are same, we just need to pick any one column.\n",
    "        raw_feature_train_count = raw_feature_train_count.iloc[:,0]\n",
    "\n",
    "        #getting time delta in secconds\n",
    "        time_delta = raw_feature_train_max[\"time\"] - raw_feature_train_min[\"time\"] \n",
    "        time_delta = time_delta.apply(timedelta.total_seconds)\n",
    "        \n",
    "        \n",
    "        raw_feature_train = pd.concat([  raw_feature_train_min.loc[:,feature_list], \n",
    "                                         raw_feature_train_max.loc[:, feature_list],\n",
    "                                         raw_feature_train_mean.loc[:, feature_list],\n",
    "                                         raw_feature_train_median.loc[:, feature_list],\n",
    "                                         raw_feature_train_sum.loc[:, feature_list],\n",
    "                                         time_delta,\n",
    "                                         raw_feature_train_count], \n",
    "                                         axis=1,\n",
    "                                         ignore_index=True)\n",
    "        \n",
    "        # preparing column list and renaming the columns.\n",
    "        column_list = [file + \"_\"+feature + \"_min\" for feature in feature_list]\n",
    "        column_list = column_list + [file + \"_\"+feature + \"_max\" for feature in feature_list]\n",
    "        column_list = column_list + [file + \"_\"+feature + \"_mean\" for feature in feature_list]\n",
    "        column_list = column_list + [file + \"_\"+feature + \"_median\" for feature in feature_list]\n",
    "        column_list = column_list + [file + \"_\"+feature + \"_sum\" for feature in feature_list]\n",
    "        column_list = column_list + [file + \"_time_delta\"]\n",
    "        column_list = column_list + [file + \"_count\"]\n",
    "        raw_feature_train.columns = column_list\n",
    "        \n",
    "        # Reseeting Index\n",
    "        raw_feature_train.reset_index(drop=True, inplace=True)\n",
    "\n",
    "        feature_train_list.append(raw_feature_train)\n",
    "    \n",
    "    \n",
    "    #splitting stress labels. Need to do this only once, since stress level will be the same for all features.\n",
    "    stress_levels = raw_feature_train_min[\"stress_level\"]\n",
    "    stress_levels.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    # grabbing the student_id.\n",
    "    student_id = raw_feature_train_min[\"student_id\"]\n",
    "    student_id.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    # concatenating every thing for final dataset.\n",
    "    concatenated_train = pd.concat([student_id]+feature_train_list+[stress_levels], axis=1)\n",
    "    \n",
    "    var_exists = 'train_set' in locals() or 'train_set' in globals()\n",
    "    \n",
    "    if var_exists:\n",
    "        train_set = train_set.append(other=concatenated_train, ignore_index=True)\n",
    "    else:\n",
    "        train_set = pd.DataFrame(concatenated_train)\n",
    "\n",
    "os.chdir(data_dir+'/VarableLength Aggregates')\n",
    "train_set.to_csv(\"variable_interval_aggregate_train.csv\", index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
